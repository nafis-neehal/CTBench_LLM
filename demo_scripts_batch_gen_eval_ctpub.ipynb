{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the whole benchmark on CT-Pub Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import module, secret_keys\n",
    "from model_list import models\n",
    "import pandas as pd\n",
    "\n",
    "hf_api_key             = secret_keys.HF_TOKEN                   #<insert your own huggingface token here>\n",
    "openai_api_key         = secret_keys.OPENAI_API_KEY_TEAM        #<insert your own openai token here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three IDs are three-shot example IDs in each dataset - ['NCT00000620', 'NCT01483560', 'NCT04280783']. Do not run generation or evaluation on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCTId</th>\n",
       "      <th>BriefTitle</th>\n",
       "      <th>EligibilityCriteria</th>\n",
       "      <th>BriefSummary</th>\n",
       "      <th>Conditions</th>\n",
       "      <th>Interventions</th>\n",
       "      <th>PrimaryOutcomes</th>\n",
       "      <th>TrialGroup</th>\n",
       "      <th>API_BaselineMeasures</th>\n",
       "      <th>API_BaselineMeasures_Corrected</th>\n",
       "      <th>Paper_BaselineMeasures</th>\n",
       "      <th>Paper_BaselineMeasures_Corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00000620</td>\n",
       "      <td>Action to Control Cardiovascular Risk in Diabe...</td>\n",
       "      <td>Inclusion Criteria:\\n\\n* Diagnosed with type 2...</td>\n",
       "      <td>The purpose of this study is to prevent major ...</td>\n",
       "      <td>Atherosclerosis, Cardiovascular Diseases, Hype...</td>\n",
       "      <td>Anti-hyperglycemic Agents, Anti-hypertensive A...</td>\n",
       "      <td>First Occurrence of a Major Cardiovascular Eve...</td>\n",
       "      <td>hypertension</td>\n",
       "      <td>Age, Continuous, Gender, Ethnicity (NIH/OMB), ...</td>\n",
       "      <td>`Age, Continuous`, `Gender`, `Ethnicity (NIH/O...</td>\n",
       "      <td>Age, Female sex, Median duration of diabetes, ...</td>\n",
       "      <td>`Age`, `Female sex`, `Median duration of diabe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00126737</td>\n",
       "      <td>Home-Based Exercise and Weight Control Program...</td>\n",
       "      <td>Inclusion Criteria:\\n\\n* Male \\&amp; female 50 yea...</td>\n",
       "      <td>The purpose of this study is to determine whet...</td>\n",
       "      <td>Chronic Diseases, Obesity, Osteoarthritis, Pain,</td>\n",
       "      <td>Weight Control Nutritional Program, Home-based...</td>\n",
       "      <td>WOMAC Function, Physical Scale SF-36v, Mental ...</td>\n",
       "      <td>obesity</td>\n",
       "      <td>Age, Continuous, Sex: Female, Male, Race/Ethni...</td>\n",
       "      <td>`Age, Continuous`, `Sex: Female, Male`, `Race/...</td>\n",
       "      <td>Age, Duration of OA, Kellgren-Lawrence Classif...</td>\n",
       "      <td>`Age`, `Duration of OA`, `Kellgren-Lawrence Cl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NCTId                                         BriefTitle  \\\n",
       "0  NCT00000620  Action to Control Cardiovascular Risk in Diabe...   \n",
       "1  NCT00126737  Home-Based Exercise and Weight Control Program...   \n",
       "\n",
       "                                 EligibilityCriteria  \\\n",
       "0  Inclusion Criteria:\\n\\n* Diagnosed with type 2...   \n",
       "1  Inclusion Criteria:\\n\\n* Male \\& female 50 yea...   \n",
       "\n",
       "                                        BriefSummary  \\\n",
       "0  The purpose of this study is to prevent major ...   \n",
       "1  The purpose of this study is to determine whet...   \n",
       "\n",
       "                                          Conditions  \\\n",
       "0  Atherosclerosis, Cardiovascular Diseases, Hype...   \n",
       "1  Chronic Diseases, Obesity, Osteoarthritis, Pain,    \n",
       "\n",
       "                                       Interventions  \\\n",
       "0  Anti-hyperglycemic Agents, Anti-hypertensive A...   \n",
       "1  Weight Control Nutritional Program, Home-based...   \n",
       "\n",
       "                                     PrimaryOutcomes    TrialGroup  \\\n",
       "0  First Occurrence of a Major Cardiovascular Eve...  hypertension   \n",
       "1  WOMAC Function, Physical Scale SF-36v, Mental ...       obesity   \n",
       "\n",
       "                                API_BaselineMeasures  \\\n",
       "0  Age, Continuous, Gender, Ethnicity (NIH/OMB), ...   \n",
       "1  Age, Continuous, Sex: Female, Male, Race/Ethni...   \n",
       "\n",
       "                      API_BaselineMeasures_Corrected  \\\n",
       "0  `Age, Continuous`, `Gender`, `Ethnicity (NIH/O...   \n",
       "1  `Age, Continuous`, `Sex: Female, Male`, `Race/...   \n",
       "\n",
       "                              Paper_BaselineMeasures  \\\n",
       "0  Age, Female sex, Median duration of diabetes, ...   \n",
       "1  Age, Duration of OA, Kellgren-Lawrence Classif...   \n",
       "\n",
       "                    Paper_BaselineMeasures_Corrected  \n",
       "0  `Age`, `Female sex`, `Median duration of diabe...  \n",
       "1  `Age`, `Duration of OA`, `Kellgren-Lawrence Cl...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pub = pd.read_csv('data_new/CT-Pub-With-Examples-Corrected.csv')\n",
    "print(data_pub.shape)\n",
    "data_pub.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation using GPT-4o with 0-shot prompts (CT-Pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [03:27,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "model_name   = models['gpt-4o']\n",
    "\n",
    "data_pub['gpt4o_zs_gen'] = None\n",
    "\n",
    "for index, row in tqdm(data_pub.iterrows()):\n",
    "    system_message, question = module.build_zeroshot_prompt(data_pub, row)\n",
    "    gen_model_query = module.system_user_template(system_message, question)\n",
    "    gen_model_response = module.run_generation_single_openai(gen_model_query, model_name, \n",
    "                                                openai_api_key, temperature=0.0)\n",
    "    \n",
    "    data_pub.at[index, 'gpt4o_zs_gen'] = gen_model_response\n",
    "\n",
    "    # print(system_message)\n",
    "    # print(question)\n",
    "    # print(gen_model_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation using GPT-4o with 3-shot prompts (CT-Pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [09:32,  5.56s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name   = models['gpt-4o']\n",
    "\n",
    "data_pub['gpt4o_ts_gen'] = None\n",
    "\n",
    "for index, row in tqdm(data_pub.iterrows()):\n",
    "    system_message, question = module.build_three_shot_prompt(data_pub, row, ref_col_name='Paper_BaselineMeasures_Corrected')\n",
    "    model_query = module.system_user_template(system_message, question)\n",
    "    model_response = module.run_generation_single_openai(model_query, model_name, \n",
    "                                                    openai_api_key, temperature=0.0)\n",
    "    \n",
    "    data_pub.at[index, 'gpt4o_ts_gen'] = model_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation using Llama3-70B-it with 0-shot prompts (CT-Pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [05:17,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "model_hf_endpoint = models['llama3-70b-it']\n",
    "\n",
    "data_pub['llama3_70b_it_zs_gen'] = None\n",
    "\n",
    "for index, row in tqdm(data_pub.iterrows()):\n",
    "\n",
    "    system_message, question = module.build_zeroshot_prompt(data_pub, row)\n",
    "    model_query = module.system_user_template(system_message, question)\n",
    "    model_response = module.run_generation_single_hf_models(model_query, model_hf_endpoint, \n",
    "                                                    hf_api_key, temperature=0.0)\n",
    "    \n",
    "    data_pub.at[index, 'llama3_70b_it_zs_gen'] = model_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation using Llama3-70B-it with 3-shot prompts (CT-Pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [05:23,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "model_hf_endpoint = models['llama3-70b-it']\n",
    "\n",
    "data_pub['llama3_70b_it_ts_gen'] = None\n",
    "\n",
    "for index, row in tqdm(data_pub.iterrows()):\n",
    "\n",
    "    system_message, question = module.build_three_shot_prompt(data_pub, row, ref_col_name='Paper_BaselineMeasures_Corrected')\n",
    "    model_query = module.system_user_template(system_message, question)\n",
    "    model_response = module.run_generation_single_hf_models(model_query, model_hf_endpoint, \n",
    "                                                    hf_api_key, temperature=0.0)\n",
    "    \n",
    "    data_pub.at[index, 'llama3_70b_it_ts_gen'] = model_response\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pub.to_csv('hidden_data/CT-Pub-With-Examples-Corrected-allgen.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pub = pd.read_csv('hidden_data/CT-Pub-With-Examples-Corrected-allgen.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Reference VS Candidate Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_pub = pd.DataFrame()\n",
    "eval_data_pub['NCTId'] = data_pub['NCTId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: eval_model_response from GPT-4o is coming in string format with JSON structure. You need to use json.loads() to use it as a json object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:15,  6.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(data_pub.iterrows()):\n",
    "\n",
    "    qstart = module.get_question_from_row(row)\n",
    "\n",
    "    reference_list = module.extract_elements_v2(row['Paper_BaselineMeasures_Corrected'])\n",
    "    \n",
    "    candidate_gzs = module.extract_elements_v2(row['gpt4o_zs_gen'])\n",
    "    candidate_gts = module.extract_elements_v2(row['gpt4o_ts_gen'])\n",
    "    candidate_lzs = module.extract_elements_v2(row['llama3_70b_it_zs_gen'])\n",
    "    candidate_lts = module.extract_elements_v2(row['llama3_70b_it_ts_gen'])\n",
    "    \n",
    "    system_message_gzs, question_gzs = module.build_gpt4_eval_prompt_with_example(reference_list, \n",
    "                                                            candidate_gzs, \n",
    "                                                            qstart)\n",
    "    \n",
    "    system_message_gts, question_gts = module.build_gpt4_eval_prompt_with_example(reference_list,\n",
    "                                                            candidate_gts,\n",
    "                                                            qstart)\n",
    "    \n",
    "    system_message_lzs, question_lzs = module.build_gpt4_eval_prompt_with_example(reference_list,\n",
    "                                                            candidate_lzs,\n",
    "                                                            qstart)\n",
    "    \n",
    "    system_message_lts, question_lts = module.build_gpt4_eval_prompt_with_example(reference_list,\n",
    "                                                            candidate_lts,\n",
    "                                                            qstart)\n",
    "\n",
    "    \n",
    "    eval_model_response_gzs = module.run_evaluation_with_gpt4o(system_message_gzs, question_gzs, openai_api_key)\n",
    "    eval_model_response_gts = module.run_evaluation_with_gpt4o(system_message_gts, question_gts, openai_api_key)\n",
    "    eval_model_response_lzs = module.run_evaluation_with_gpt4o(system_message_lzs, question_lzs, openai_api_key)\n",
    "    eval_model_response_lts = module.run_evaluation_with_gpt4o(system_message_lts, question_lts, openai_api_key)\n",
    "    \n",
    "    #Convert eval_model_response to a JSON string and store in the dataframe\n",
    "    eval_data_pub.at[index, 'gpt4o_zs_gen_matches'] = eval_model_response_gzs \n",
    "    eval_data_pub.at[index, 'gpt4o_ts_gen_matches'] = eval_model_response_gts\n",
    "    eval_data_pub.at[index, 'llama3_70b_it_zs_gen_matches'] = eval_model_response_lzs\n",
    "    eval_data_pub.at[index, 'llama3_70b_it_ts_gen_matches'] = eval_model_response_lts\n",
    "\n",
    "    #break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_pub.to_csv('hidden_data/CT-Pub-With-Examples-Corrected-allgpteval-eval-prompt-edited.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctbench_scripts_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
